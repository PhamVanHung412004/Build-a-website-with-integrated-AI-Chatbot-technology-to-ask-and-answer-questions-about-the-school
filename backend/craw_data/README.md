# BTEC FPT Web Crawler

Má»™t cÃ´ng cá»¥ crawler máº¡nh máº½ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho website BTEC FPT (https://btec.fpt.edu.vn/), há»— trá»£ thu tháº­p toÃ n bá»™ ná»™i dung vÃ  xuáº¥t thÃ nh file PDF.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **Thu tháº­p toÃ n diá»‡n**: Crawl toÃ n bá»™ website má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng
- **Xá»­ lÃ½ tiáº¿ng Viá»‡t**: Há»— trá»£ Ä‘áº§y Ä‘á»§ ná»™i dung tiáº¿ng Viá»‡t vÃ  Unicode
- **Táº¡o PDF cháº¥t lÆ°á»£ng cao**: Chuyá»ƒn Ä‘á»•i tá»«ng trang web thÃ nh file PDF riÃªng biá»‡t
- **Táº£i PDF cÃ³ sáºµn**: Tá»± Ä‘á»™ng táº£i xuá»‘ng cÃ¡c file PDF Ä‘Ã£ cÃ³ trÃªn website
- **PhÃ¢n loáº¡i theo campus**: Tá»• chá»©c ná»™i dung theo cÃ¡c campus (HÃ  Ná»™i, HCM, ÄÃ  Náºµng)
- **Xá»­ lÃ½ lá»—i thÃ´ng minh**: Retry tá»± Ä‘á»™ng vÃ  ghi log chi tiáº¿t
- **Kiá»ƒm soÃ¡t Ä‘á»“ng thá»i**: Crawl nhiá»u trang cÃ¹ng lÃºc vá»›i giá»›i háº¡n cÃ³ thá»ƒ cáº¥u hÃ¬nh
- **Loáº¡i bá» trÃ¹ng láº·p**: PhÃ¡t hiá»‡n vÃ  bá» qua ná»™i dung trÃ¹ng láº·p

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8 trá»Ÿ lÃªn
- Há»‡ Ä‘iá»u hÃ nh: Windows, macOS, hoáº·c Linux
- RAM: Tá»‘i thiá»ƒu 4GB
- Dung lÆ°á»£ng Ä‘Ä©a: TÃ¹y thuá»™c vÃ o sá»‘ lÆ°á»£ng trang cáº§n crawl

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. Clone hoáº·c táº£i code

```bash
# Táº¡o thÆ° má»¥c dá»± Ã¡n
mkdir btec_crawler
cd btec_crawler

# Copy file btec_crawler.py vÃ o thÆ° má»¥c nÃ y
```

### 2. Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹)

```bash
conda create -n ten_moi_truong python=3.10
conda activate ten_moi_truong
```

### 3. CÃ i Ä‘áº·t dependencies

Táº¡o file `requirements.txt` vá»›i ná»™i dung sau:

```txt
aiohttp>=3.8.0
asyncio>=3.4.3
beautifulsoup4>=4.12.0
weasyprint>=60.0
playwright>=1.40.0
tenacity>=8.2.0
requests>=2.31.0
lxml>=4.9.0
Pillow>=10.0.0
pdfkit>=1.0.0
urllib3>=2.0.0
```

Sau Ä‘Ã³ cÃ i Ä‘áº·t:

```bash
pip install -r requirements.txt
```

### 4. CÃ i Ä‘áº·t Playwright browsers (náº¿u sá»­ dá»¥ng Playwright engine)

```bash
playwright install chromium
```

### 5. CÃ i Ä‘áº·t wkhtmltopdf (náº¿u sá»­ dá»¥ng pdfkit engine)

- **Windows**: Táº£i tá»« https://wkhtmltopdf.org/downloads.html
- **macOS**: `brew install wkhtmltopdf`
- **Linux**: `sudo apt-get install wkhtmltopdf`

## ğŸš¦ CÃ¡ch sá»­ dá»¥ng

### Sá»­ dá»¥ng cÆ¡ báº£n

```python
import asyncio
from btec_crawler import BTECCrawler

async def main():
    # Sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
    async with BTECCrawler() as crawler:
        report = await crawler.crawl_website()
        print(f"ÄÃ£ crawl {report['summary']['total_pages_crawled']} trang")

if __name__ == "__main__":
    asyncio.run(main())
```

### Sá»­ dá»¥ng vá»›i cáº¥u hÃ¬nh tÃ¹y chá»‰nh

```python
import asyncio
from btec_crawler import BTECCrawler

async def main():
    config = {
        'max_concurrent_requests': 5,  # Sá»‘ request Ä‘á»“ng thá»i
        'delay_between_requests': 2.0,  # Delay giá»¯a cÃ¡c request (giÃ¢y)
        'output_dir': './my_output',    # ThÆ° má»¥c lÆ°u káº¿t quáº£
        'pdf_engine': 'weasyprint',     # Engine táº¡o PDF
        'max_depth': 10,                # Äá»™ sÃ¢u crawl tá»‘i Ä‘a
        'download_existing_pdfs': True  # Táº£i PDF cÃ³ sáºµn
    }
    
    async with BTECCrawler(config) as crawler:
        report = await crawler.crawl_website()

if __name__ == "__main__":
    asyncio.run(main())
```

### Crawl cÃ¡c URL cá»¥ thá»ƒ

```python
async def main():
    seed_urls = [
        'https://btec.fpt.edu.vn/courses',
        'https://btec.fpt.edu.vn/btec-hanoi',
        'https://btec.fpt.edu.vn/admissions'
    ]
    
    async with BTECCrawler() as crawler:
        report = await crawler.crawl_website(seed_urls)
```

## âš™ï¸ Cáº¥u hÃ¬nh chi tiáº¿t

### CÃ¡c tÃ¹y chá»n cáº¥u hÃ¬nh

| TÃ¹y chá»n | MÃ´ táº£ | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh |
|----------|-------|------------------|
| `base_url` | URL gá»‘c cá»§a website | `https://btec.fpt.edu.vn/` |
| `max_concurrent_requests` | Sá»‘ request Ä‘á»“ng thá»i tá»‘i Ä‘a | `5` |
| `delay_between_requests` | Thá»i gian chá» giá»¯a cÃ¡c request (giÃ¢y) | `1.0` |
| `max_retries` | Sá»‘ láº§n thá»­ láº¡i khi gáº·p lá»—i | `3` |
| `timeout` | Timeout cho má»—i request (giÃ¢y) | `30` |
| `max_depth` | Äá»™ sÃ¢u crawl tá»‘i Ä‘a | `10` |
| `output_dir` | ThÆ° má»¥c lÆ°u káº¿t quáº£ | `./btec_crawl_output` |
| `pdf_engine` | Engine táº¡o PDF (`weasyprint`, `playwright`) | `weasyprint` |
| `include_images` | Bao gá»“m hÃ¬nh áº£nh trong PDF | `True` |
| `download_existing_pdfs` | Táº£i xuá»‘ng file PDF cÃ³ sáºµn | `True` |
| `respect_robots_txt` | TuÃ¢n thá»§ robots.txt | `True` |

### VÃ­ dá»¥ file cáº¥u hÃ¬nh JSON

Táº¡o file `config.json`:

```json
{
  "base_url": "https://btec.fpt.edu.vn/",
  "max_concurrent_requests": 3,
  "delay_between_requests": 2.0,
  "max_retries": 3,
  "timeout": 30,
  "max_depth": 8,
  "output_dir": "./btec_output",
  "pdf_engine": "weasyprint",
  "download_existing_pdfs": true,
  "pdf_options": {
    "page_size": "A4",
    "margin": "1in",
    "orientation": "Portrait"
  }
}
```

Sá»­ dá»¥ng vá»›i file config:

```python
import json

with open('config.json', 'r') as f:
    config = json.load(f)

async with BTECCrawler(config) as crawler:
    report = await crawler.crawl_website()
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c output

```
btec_crawl_output/
â”œâ”€â”€ pages_pdf/              # PDF Ä‘Æ°á»£c táº¡o tá»« cÃ¡c trang web
â”œâ”€â”€ downloaded_pdfs/        # PDF Ä‘Æ°á»£c táº£i xuá»‘ng
â”œâ”€â”€ campus_hanoi/          # Ná»™i dung campus HÃ  Ná»™i
â”œâ”€â”€ campus_hcm/            # Ná»™i dung campus HCM
â”œâ”€â”€ campus_danang/         # Ná»™i dung campus ÄÃ  Náºµng
â”œâ”€â”€ reports/               # BÃ¡o cÃ¡o crawl
â”‚   â””â”€â”€ crawl_report_*.json
â””â”€â”€ logs/                  # Log file
    â””â”€â”€ btec_crawler.log
```

## ğŸ“Š BÃ¡o cÃ¡o káº¿t quáº£

Sau khi crawl xong, tool sáº½ táº¡o bÃ¡o cÃ¡o JSON vá»›i cÃ¡c thÃ´ng tin:

- Tá»•ng sá»‘ trang Ä‘Ã£ crawl
- Sá»‘ PDF Ä‘Ã£ táº¡o
- Sá»‘ PDF Ä‘Ã£ táº£i xuá»‘ng
- Sá»‘ lá»—i gáº·p pháº£i
- Thá»‘ng kÃª theo campus
- Danh sÃ¡ch URL lá»—i (náº¿u cÃ³)
- Thá»i gian thá»±c hiá»‡n

## ğŸ”§ Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### 1. Lá»—i cÃ i Ä‘áº·t WeasyPrint

```bash
# Ubuntu/Debian
sudo apt-get install python3-pip python3-cffi python3-brotli libpango-1.0-0 libharfbuzz0b libpangoft2-1.0-0

# macOS
brew install cairo pango gdk-pixbuf libffi
```

### 2. Lá»—i SSL Certificate

ThÃªm vÃ o config:
```python
config = {
    'verify_ssl': False  # Chá»‰ dÃ¹ng khi cáº§n thiáº¿t
}
```

### 3. Memory Error vá»›i website lá»›n

Giáº£m concurrent requests vÃ  tÄƒng delay:
```python
config = {
    'max_concurrent_requests': 2,
    'delay_between_requests': 3.0
}
```

## ğŸš¨ LÆ°u Ã½ quan trá»ng

1. **TÃ´n trá»ng server**: KhÃ´ng Ä‘áº·t `max_concurrent_requests` quÃ¡ cao
2. **Kiá»ƒm tra robots.txt**: Tool máº·c Ä‘á»‹nh tuÃ¢n thá»§ robots.txt
3. **Backup Ä‘á»‹nh ká»³**: Vá»›i crawl lá»›n, nÃªn backup káº¿t quáº£ Ä‘á»‹nh ká»³
4. **Monitor resources**: Theo dÃµi CPU vÃ  RAM khi crawl
5. **Test nhá» trÆ°á»›c**: Thá»­ vá»›i má»™t vÃ i URL trÆ°á»›c khi crawl toÃ n bá»™

## ğŸ¤ ÄÃ³ng gÃ³p

Náº¿u báº¡n muá»‘n Ä‘Ã³ng gÃ³p hoáº·c bÃ¡o lá»—i, vui lÃ²ng:

1. Fork repository
2. Táº¡o branch má»›i (`git checkout -b feature/AmazingFeature`)
3. Commit thay Ä‘á»•i (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

## ğŸ“ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c. Vui lÃ²ng tuÃ¢n thá»§ Ä‘iá»u khoáº£n sá»­ dá»¥ng cá»§a website khi sá»­ dá»¥ng tool nÃ y.

## ğŸ“ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á» khi sá»­ dá»¥ng, báº¡n cÃ³ thá»ƒ:

1. Kiá»ƒm tra file log trong thÆ° má»¥c `logs/`
2. Xem láº¡i cáº¥u hÃ¬nh
3. Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t Ä‘á»§ dependencies
4. Thá»­ vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh trÆ°á»›c

---

Made with â¤ï¸ for BTEC FPT students and staff